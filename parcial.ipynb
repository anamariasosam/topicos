{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn import cluster\n",
    "\n",
    "X,Y = datasets.make_multilabel_classification(n_samples=100, n_features=10, n_classes=3, n_labels=1, length=50, allow_unlabeled=False, sparse=False, return_indicator='dense',return_distributions=False, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a separar los datos para que tengan de a una sola etiqueta, así se dupliquen los datos\n",
    "x_vals = list()\n",
    "y_vals = list()\n",
    "\n",
    "# Seleccionar a que clase o clases pertenece cada observacion \n",
    "def single_class(clase) :\n",
    "    indices = list()\n",
    "    for i, val in enumerate(Y):\n",
    "        # Si ese valor es igual a 1 es porque pertenece\n",
    "        if val[clase-1] == 1:\n",
    "            indices.append(i)\n",
    "            y_vals.append(clase)\n",
    "    return X[indices]\n",
    "\n",
    "# Ahora vamos a usar el metodo de arriba para asignarle a una observación una sola clase\n",
    "# Eran 100 observaciones ahora tengo 154, revisando las etiquetas Y me di cuenta que en realidad eran pocas las muestras\n",
    "# con doble y triple clase asi que decidí separarlas, ahora tengo 3 etiquetas 1,2,3 . Si tiene la etiqueta 1 es porque p\n",
    "# pertenece a la clase 1, 2 a la clase 2 y 3 a la clase 3\n",
    "c1 = single_class(1)\n",
    "c2 = single_class(2)\n",
    "c3 = single_class(3)\n",
    "\n",
    "x_vals = np.concatenate((c1, c2, c3), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestras iguales 26/44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anasosa/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = x_vals\n",
    "y = y_vals\n",
    "\n",
    "# Separar los datos de entranamiento y los de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "# Tecnica de remoción es la mejor!!!\n",
    "def remocion_train(X) :\n",
    "    X = X - X.mean(axis=0)\n",
    "    X = X/X.std(axis=0)\n",
    "\n",
    "    return X\n",
    "\n",
    "def remocion_test(X_test) :\n",
    "    media = X_train.mean(axis=0)\n",
    "    desviacion = X_train.std(axis=0)\n",
    "\n",
    "    X_test = X_test - media\n",
    "    X_test = X_test/desviacion\n",
    "\n",
    "    return X_test\n",
    "\n",
    "# Aplico el metodo de remocion para entranamiento y para test\n",
    "x_train_norm = remocion_train(X_train)\n",
    "x_test_norm = remocion_test(X_test)\n",
    "\n",
    "# Realizo una regresión logística con los datos ya preprocesados\n",
    "\n",
    "# entreno los datos\n",
    "clasificador = LogisticRegression(C=10.0, random_state=0)\n",
    "clasificador.fit(x_train_norm, y_train)\n",
    "\n",
    "\n",
    "y_predict = clasificador.predict(x_test_norm)\n",
    "iguales = (y_test == y_predict).sum()\n",
    "acc = 100.0*(y_predict == y_test).sum()/X_test.shape[0]\n",
    "\n",
    "print('Muestras iguales %d/%d' %( iguales, len(y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
