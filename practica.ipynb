{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Técnicas\n",
      "1 - Remoción\n",
      "2 - Binarización\n",
      "3 - Escalamiento\n",
      "4 - Normalizacion L1\n",
      "5 - Normalizacion L2\n",
      "Que técnica desea realizar? 2\n",
      "\n",
      "- Binarización - \n",
      "\n",
      "El acc de clasificacion es del  46.6666666667 %\n",
      "El acc de clasificacion es del  46.6666666667 %\n",
      "El acc de clasificacion es del  46.6666666667 %\n",
      "El acc de clasificacion es del  46.6666666667 %\n",
      "El acc de clasificacion es del  46.6666666667 %\n",
      "El acc de clasificacion es del  46.6666666667 %\n",
      "El acc de clasificacion es del  46.6666666667 %\n",
      "El acc de clasificacion es del  46.6666666667 %\n",
      "El acc de clasificacion es del  46.6666666667 %\n",
      "El acc de clasificacion es del  46.6666666667 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIAEwQAASBAMAIAEwQAASPw/3r5vr/zUwREAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118e14828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importar los datos desde texto plano separado por comas\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn import cross_validation\n",
    "\n",
    "from numpy import linalg as LA\n",
    "\n",
    "# Datos de archivo\n",
    "# archivo_entrada = 'Data.txt' \n",
    "# datos = np.loadtxt(archivo_entrada, delimiter=',') \n",
    "# Si le etiqueta esta en la primera posicion \n",
    "# X,y = datos[:, 1:], datos[:, 0]\n",
    "\n",
    "# Importar data de sklearn\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,[0,1]]\n",
    "y = iris.target\n",
    "\n",
    "# Separar los datos de entranamiento y los de test\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y, test_size=0.2, random_state=3)\n",
    "\n",
    "\n",
    "# Tecnica de remoción\n",
    "def remocion_train(X) :\n",
    "    X = X - X.mean(axis=0)\n",
    "    X = X/X.std(axis=0)\n",
    "\n",
    "    return X\n",
    "\n",
    "def remocion_test(X_test) :\n",
    "    media = X_train.mean(axis=0)\n",
    "    desviacion = X_train.std(axis=0)\n",
    "\n",
    "    X_test = X_test - media\n",
    "    X_test = X_test/desviacion\n",
    "\n",
    "    return X_test\n",
    "\n",
    "# Tecnica de Binarizacion\n",
    "def binarizacion(X,gamma) :\n",
    "    filas = np.shape(X)[0]\n",
    "    columnas = np.shape(X)[1]\n",
    "\n",
    "    for i in range(filas) :\n",
    "        for j in range(columnas) :\n",
    "            X[i][j] = 1 if X[i][j] >= gamma else 0\n",
    "\n",
    "    return X\n",
    "\n",
    "# Tecnica de Escalamiento\n",
    "def escalamiento(X) :\n",
    "    X = X - X.min(axis=0)\n",
    "    X = X/(X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "    return X\n",
    "\n",
    "# normalizacion l1\n",
    "def normalizacion_uno(X) :\n",
    "    norm = LA.norm(X, ord=1, axis=1)\n",
    "\n",
    "    filas = np.shape(X)[0]\n",
    "    columnas = np.shape(X)[1]\n",
    "\n",
    "    for i in range(filas) :\n",
    "        X[i][:] =  X[i][:] / norm[i]\n",
    "    return X\n",
    "\n",
    "# normalizacion l2\n",
    "def normalizacion_dos(X) :\n",
    "    norm = LA.norm(X, ord=2, axis=1)\n",
    "\n",
    "    filas = np.shape(X)[0]\n",
    "    columnas = np.shape(X)[1]\n",
    "\n",
    "    for i in range(filas) :\n",
    "        for j in range(columnas) :\n",
    "            X[i][j] =  X[i][j] / norm[i]\n",
    "    return X\n",
    "\n",
    "def graficar_clasificador(clasificador, X, y):\n",
    "    # definimos valores máximos y mínimos de la malla que vamos a graficar\n",
    "    min_x, max_x = X[:,0].min() - 1.0 , X[:,0].max() + 1.0\n",
    "    min_y, max_y = X[:,1].min() - 1.0 , X[:,1].max() + 1.0\n",
    "    \n",
    "    paso = 0.01\n",
    "    \n",
    "    x_vals, y_vals = np.mgrid[min_x:max_x:paso, min_y:max_y:paso]\n",
    "    \n",
    "    # corremos el clasificador sobre la malla\n",
    "    resultados = clasificador.predict(np.c_[x_vals.ravel(), y_vals.ravel()])\n",
    "    \n",
    "    resultados = resultados.reshape(x_vals.shape)\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    plt.pcolormesh(x_vals, y_vals, resultados, cmap=plt.cm.Pastel1)\n",
    "    plt.scatter(X[:,0], X[:,1],c=y, s=75, edgecolors='black', linewidth=1, cmap=plt.cm.Set2 )\n",
    "    plt.xlim(x_vals.min(), x_vals.max())\n",
    "    plt.ylim(y_vals.min(), y_vals.max())\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def resultados_clasficador(x_train_norm, x_test_norm) :\n",
    "    valores_de_c =[ 1,10,100,200,300,450,550,800,950,1000]\n",
    "    \n",
    "    for c in valores_de_c :\n",
    "        clasificador =  GaussianNB()\n",
    "        clasificador.fit(x_train_norm, y_train)\n",
    "        y_pred = clasificador.predict(x_test_norm)\n",
    "        iguales = (y_test != y_pred).sum()\n",
    "        porcentaje = (iguales/45)*100\n",
    "        \n",
    "        acc = 100.0*(y_pred == y_test).sum()/x_test_norm.shape[0]\n",
    "        print('El acc de clasificacion es del ', acc, '%')\n",
    "       # print('C = %d - muestras iguales %d/%d - Porcentaje: %d ' %(c, iguales, len(y_pred), porcentaje))\n",
    "    \n",
    "    graficar_clasificador(clasificador, x_test_norm, y_test)\n",
    "\n",
    "print(\"Técnicas\\n1 - Remoción\\n2 - Binarización\\n3 - Escalamiento\\n4 - Normalizacion L1\\n5 - Normalizacion L2\")\n",
    "tecnica = int(input('Que técnica desea realizar? '))\n",
    "\n",
    "if tecnica == 1:\n",
    "    print('\\n- Remoción - \\n')\n",
    "    x_train_norm = remocion_train(X_train)\n",
    "    x_test_norm = remocion_test(X_test)\n",
    "elif tecnica == 2:\n",
    "    print('\\n- Binarización - \\n')\n",
    "    gamma = ( X_train.min() + X_train.max())/2\n",
    "    x_train_norm =  binarizacion(X_train, gamma)\n",
    "    x_test_norm =  binarizacion(X_test, gamma)\n",
    "elif tecnica == 3:\n",
    "    print('\\n- Escalamiento - \\n')\n",
    "    x_train_norm = escalamiento(X_train)\n",
    "    x_test_norm = escalamiento(X_test)\n",
    "elif tecnica == 4:\n",
    "    print('\\n- Normalizacion L1 - \\n')\n",
    "    x_train_norm = normalizacion_uno(X_train)\n",
    "    x_test_norm = normalizacion_uno(X_test)\n",
    "elif tecnica == 5:\n",
    "    print('\\n- Normalizacion L2 - \\n')\n",
    "    x_train_norm = normalizacion_dos(X_train)\n",
    "    x_test_norm = normalizacion_dos(X_test)\n",
    "\n",
    "    \n",
    "    \n",
    "resultados_clasficador(x_train_norm, x_test_norm)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
